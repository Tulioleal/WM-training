# ============================================================================
# CI/CD - Training Job via Vertex AI (On-Demand)
# ============================================================================
#
# Disparar manualmente desde: Actions ‚Üí Training Job ‚Üí Run workflow
# Requiere que la imagen ya exista en Artifact Registry (ver build.yaml)
#
# Flujo:
#   1. Lanza un Custom Job en Vertex AI con GPU
#   2. El container descarga datos de GCS, entrena, sube modelo a GCS
#   3. Registra el modelo en la DB
#   4. Reinicia la API en GKE para cargar el nuevo modelo
#
# ============================================================================

name: Training Job

on:
  workflow_dispatch:
    inputs:
      epochs:
        description: 'N√∫mero de epochs'
        default: '50'
        type: string
      batch_size:
        description: 'Batch size'
        default: '16'
        type: string
      patience:
        description: 'Early stopping patience'
        default: '10'
        type: string
      all_time:
        description: 'Usar TODAS las inferencias (ignorar √∫ltimo training)'
        default: false
        type: boolean
      gpu_type:
        description: 'Tipo de GPU'
        default: 'NVIDIA_TESLA_T4'
        type: choice
        options:
          - NVIDIA_TESLA_T4
          - NVIDIA_L4

permissions:
  contents: read
  id-token: write

env:
  IMAGE_NAME: "training"
  WORKLOAD_IDENTITY_PROVIDER: "projects/${{ secrets.GCP_PROJECT_NUMBER }}/locations/global/workloadIdentityPools/github-actions-pool/providers/github-provider"

jobs:
  train:
    name: Run Training Job (Vertex AI)
    runs-on: ubuntu-latest
    environment: deploy

    steps:
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.SERVICE_ACCOUNT }}

      - name: Verify training image exists
        run: |
          gcloud artifacts docker images describe \
            ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:latest \
            --format="value(image_summary.digest)" || {
              echo "‚ùå La imagen de training no existe. Corr√© el workflow 'Build Training Image' primero."
              exit 1
            }

      - name: Build training args
        run: |
          ARGS="--from-inferences,--only-verified,--epochs=${{ inputs.epochs }},--batch-size=${{ inputs.batch_size }},--patience=${{ inputs.patience }}"
          if [ "${{ inputs.all_time }}" = "true" ]; then
            ARGS="$ARGS,--all-time"
          fi
          echo "TRAINING_ARGS=$ARGS" >> $GITHUB_ENV
          echo "üìã Training args: $ARGS"

      - name: Enable Vertex AI API
        run: |
          gcloud services enable aiplatform.googleapis.com --quiet

      - name: Launch Vertex AI Custom Job
        run: |
          JOB_NAME="waste-detection-training-$(date +%Y%m%d-%H%M%S)"

          gcloud ai custom-jobs create \
            --region=${{ vars.GCP_REGION }} \
            --display-name="$JOB_NAME" \
            --network=projects/${{ secrets.GCP_PROJECT_NUMBER }}/global/networks/waste-detection-vpc-prod \
            --worker-pool-spec=machine-type=n1-standard-4,accelerator-type=${{ inputs.gpu_type }},accelerator-count=1,container-image-uri=${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:latest \
            --args="$TRAINING_ARGS" \
            --env-vars="GCS_MODELS_BUCKET=${{ vars.GCS_MODELS_BUCKET }},GCS_IMAGES_BUCKET=${{ vars.GCS_IMAGES_BUCKET }},GCS_DATASETS_BUCKET=${{ vars.GCS_DATASETS_BUCKET }},DATABASE_URL=${{ secrets.DATABASE_URL }}" \
            --format="value(name)" > /tmp/job_name.txt

          FULL_JOB_NAME=$(cat /tmp/job_name.txt)
          echo "JOB_ID=$FULL_JOB_NAME" >> $GITHUB_ENV
          echo "‚úÖ Job lanzado: $FULL_JOB_NAME"

      - name: Wait for training to complete
        run: |
          echo "‚è≥ Esperando que el Job termine (polling cada 60s, timeout: 2h)..."
          TIMEOUT=7200
          ELAPSED=0

          while [ $ELAPSED -lt $TIMEOUT ]; do
            STATE=$(gcloud ai custom-jobs describe $JOB_ID \
              --region=${{ vars.GCP_REGION }} \
              --format="value(state)")

            echo "  Estado: $STATE (${ELAPSED}s)"

            if [ "$STATE" = "JOB_STATE_SUCCEEDED" ]; then
              echo "‚úÖ Training completado exitosamente"
              exit 0
            elif [ "$STATE" = "JOB_STATE_FAILED" ] || [ "$STATE" = "JOB_STATE_CANCELLED" ]; then
              echo "‚ùå Training fall√≥ con estado: $STATE"
              gcloud ai custom-jobs describe $JOB_ID \
                --region=${{ vars.GCP_REGION }} \
                --format="yaml(error)"
              exit 1
            fi

            sleep 60
            ELAPSED=$((ELAPSED + 60))
          done

          echo "‚ùå Timeout: el training excedi√≥ las 2 horas"
          exit 1

      - name: Show job details
        if: always()
        run: |
          gcloud ai custom-jobs describe $JOB_ID \
            --region=${{ vars.GCP_REGION }} \
            --format="yaml(displayName, state, createTime, endTime, error)"

      - name: Get GKE credentials
        if: success()
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ vars.GKE_CLUSTER }}
          location: ${{ vars.GCP_ZONE }}

      - name: Restart inference API
        if: success()
        run: |
          kubectl rollout restart deployment/inference-api -n waste-detection
          kubectl rollout status deployment/inference-api -n waste-detection --timeout=300s
          echo "‚úÖ API reiniciada con el nuevo modelo"