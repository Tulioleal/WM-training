# ============================================================================
# CI/CD - Training Job (On-Demand)
# ============================================================================
#
# Flujo:
#   1. Disparar manualmente desde GitHub Actions UI
#   2. Build y push de la imagen Docker de training
#   3. Lanza el Job de Kubernetes en GKE
#   4. Espera a que el Job termine
#   5. Reinicia la API para cargar el nuevo modelo
#
# ============================================================================

name: Training Job

on:
  workflow_dispatch:
    inputs:
      epochs:
        description: 'Número de epochs'
        default: '50'
        type: string
      batch_size:
        description: 'Batch size'
        default: '16'
        type: string
      patience:
        description: 'Early stopping patience'
        default: '10'
        type: string
      all_time:
        description: 'Usar TODAS las inferencias (ignorar último training)'
        default: false
        type: boolean

permissions:
  contents: read
  id-token: write

env:
  IMAGE_NAME: "training"
  WORKLOAD_IDENTITY_PROVIDER: "projects/${{ secrets.GCP_PROJECT_NUMBER }}/locations/global/workloadIdentityPools/github-actions-pool/providers/github-provider"

jobs:
  # ================================================================
  # Job 1: Build & Push de la imagen Docker
  # ================================================================
  build:
    name: Build Training Image
    runs-on: ubuntu-latest
    environment: deploy

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.SERVICE_ACCOUNT }}

      - name: Set image tag
        run: echo "IMAGE_TAG=sha-$(echo ${{ github.sha }} | cut -c1-7)" >> $GITHUB_ENV

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ vars.GCP_REGION }}-docker.pkg.dev --quiet

      - name: Build Docker image
        run: |
          docker build \
            -t ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }} \
            -t ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:latest \
            .

      - name: Push Docker image
        run: |
          docker push ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.IMAGE_TAG }}
          docker push ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:latest

  # ================================================================
  # Job 2: Lanzar Training Job en GKE
  # ================================================================
  train:
    name: Run Training Job
    runs-on: ubuntu-latest
    needs: build
    environment: deploy

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ vars.SERVICE_ACCOUNT }}

      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ vars.GKE_CLUSTER }}
          location: ${{ vars.GCP_ZONE }}

      - name: Build training args
        run: |
          ARGS="--from-inferences --only-verified --epochs=${{ inputs.epochs }} --batch-size=${{ inputs.batch_size }} --patience=${{ inputs.patience }}"
          if [ "${{ inputs.all_time }}" = "true" ]; then
            ARGS="$ARGS --all-time"
          fi
          echo "TRAINING_ARGS=$ARGS" >> $GITHUB_ENV

      - name: Launch training Job
        run: |
          cat <<EOF | kubectl create -f -
          apiVersion: batch/v1
          kind: Job
          metadata:
            generateName: training-job-
            namespace: waste-detection
          spec:
            backoffLimit: 2
            ttlSecondsAfterFinished: 86400
            template:
              spec:
                serviceAccountName: waste-detection-app-sa
                tolerations:
                  - key: workload
                    operator: Equal
                    value: training
                    effect: NoSchedule
                containers:
                  - name: training
                    image: ${{ vars.ARTIFACT_REGISTRY }}/${{ env.IMAGE_NAME }}:latest
                    args: [$(echo $TRAINING_ARGS | sed 's/ /", "/g' | sed 's/^/"/' | sed 's/$/"/' )]
                    envFrom:
                      - configMapRef:
                          name: infra-config
                      - secretRef:
                          name: db-credentials
                    resources:
                      requests:
                        cpu: "2"
                        memory: "8Gi"
                        nvidia.com/gpu: 1
                      limits:
                        cpu: "4"
                        memory: "12Gi"
                        nvidia.com/gpu: 1
                restartPolicy: Never
          EOF

          # Capturar el nombre del Job creado
          JOB_NAME=$(kubectl get jobs -n waste-detection --sort-by=.metadata.creationTimestamp -o jsonpath='{.items[-1].metadata.name}')
          echo "JOB_NAME=$JOB_NAME" >> $GITHUB_ENV
          echo "✅ Job lanzado: $JOB_NAME"

      - name: Wait for training to complete
        run: |
          echo "⏳ Esperando que el Job $JOB_NAME termine..."
          kubectl wait --for=condition=complete job/$JOB_NAME \
            -n waste-detection \
            --timeout=7200s || {
              echo "❌ Training falló o excedió el timeout"
              kubectl logs job/$JOB_NAME -n waste-detection --tail=50
              exit 1
            }
          echo "✅ Training completado exitosamente"

      - name: Show training logs
        if: always()
        run: |
          kubectl logs job/$JOB_NAME -n waste-detection --tail=100

      - name: Restart inference API
        if: success()
        run: |
          kubectl rollout restart deployment/inference-api -n waste-detection
          kubectl rollout status deployment/inference-api -n waste-detection --timeout=300s
          echo "✅ API reiniciada con el nuevo modelo"